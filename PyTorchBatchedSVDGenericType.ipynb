{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0yO7F8LJDYaa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure CUDA is available"
      ],
      "metadata": {
        "id": "qnYBcKJ0DdHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.cuda.is_available(), \"CUDA must be available to run this code on GPU.\"\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "okcsN9rXDiDg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "User-configurable parameters"
      ],
      "metadata": {
        "id": "VWfBpzw_-QMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dtype = torch.complex128\n",
        "dtype = torch.float64"
      ],
      "metadata": {
        "id": "mVyJF8Ua-PkL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate over the batch size"
      ],
      "metadata": {
        "id": "t5JjEowIENMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = 4               # number of rows (fixed)\n",
        "n = 4               # number of columns (fixed)\n",
        "batch_sizes = [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]  # iterate over powers of 2\n",
        "\n",
        "# Warm-up to initialize CUDA context\n",
        "warm_up = torch.randn(1, m, n, dtype=dtype, device=device)\n",
        "U, S, Vh = torch.linalg.svd(warm_up, full_matrices=False)\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "# Warm-up to initialize CUDA context\n",
        "if dtype in [torch.complex64, torch.complex128]:\n",
        "  # Generate complex data (real + imaginary parts)\n",
        "  real_part = np.random.randn(1, m, n).astype(np.float32 if dtype == torch.complex64 else np.float64)\n",
        "  imag_part = np.random.randn(1, m, n).astype(np.float32 if dtype == torch.complex64 else np.float64)\n",
        "  batch_cpu = real_part + 1j * imag_part\n",
        "else:\n",
        "  # Generate real data\n",
        "  batch_cpu = np.random.randn(1, m, n).astype(np.float32 if dtype == torch.float32 else np.float64)\n",
        "\n",
        "X = torch.from_numpy(batch_cpu).to(device=device, dtype=dtype)  # shape (B, m, n)\n",
        "torch.cuda.synchronize()  # Synchronize before starting timing\n",
        "U, S, Vh = torch.linalg.svd(X, full_matrices=False)\n",
        "torch.cuda.synchronize()  # Ensure operations complete before measuring\n",
        "\n",
        "elapsed_times = []\n",
        "avg_errors    = []\n",
        "\n",
        "for B in batch_sizes:\n",
        "    # ── 1) Create a random batch on CPU (NumPy) with specified dtype ──\n",
        "    if dtype in [torch.complex64, torch.complex128]:\n",
        "        # Generate complex data (real + imaginary parts)\n",
        "        real_part = np.random.randn(B, m, n).astype(np.float32 if dtype == torch.complex64 else np.float64)\n",
        "        imag_part = np.random.randn(B, m, n).astype(np.float32 if dtype == torch.complex64 else np.float64)\n",
        "        batch_cpu = real_part + 1j * imag_part\n",
        "    else:\n",
        "        # Generate real data\n",
        "        batch_cpu = np.random.randn(B, m, n).astype(np.float32 if dtype == torch.float32 else np.float64)\n",
        "\n",
        "    # ── 2) Move the batch to GPU as a PyTorch tensor ──\n",
        "    X = torch.from_numpy(batch_cpu).to(device=device, dtype=dtype)  # shape (B, m, n)\n",
        "\n",
        "    # ── 3) Time the batched SVD on GPU using torch.cuda.Event ──\n",
        "    start_event = torch.cuda.Event(enable_timing=True)\n",
        "    end_event   = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "    torch.cuda.synchronize()  # Synchronize before starting timing\n",
        "    start_event.record()\n",
        "    U, S, Vh = torch.linalg.svd(X, full_matrices=False)\n",
        "    end_event.record()\n",
        "    torch.cuda.synchronize()  # Ensure operations complete before measuring\n",
        "\n",
        "    elapsed_time = start_event.elapsed_time(end_event) / 1000.0  # Convert milliseconds to seconds\n",
        "    elapsed_times.append(elapsed_time)\n",
        "\n",
        "    # ── 4) Move results back to CPU for reconstruction error checking ──\n",
        "    U_cpu  = U.cpu().numpy()   # shape (B, m, k)\n",
        "    S_cpu  = S.cpu().numpy()   # shape (B, k)\n",
        "    Vh_cpu = Vh.cpu().numpy()  # shape (B, k, n)\n",
        "\n",
        "    # ── 5) Compute reconstruction errors on CPU (NumPy) ──\n",
        "    errors = []\n",
        "    k = min(m, n)\n",
        "    for i in range(B):\n",
        "        Ai = batch_cpu[i]            # Original matrix\n",
        "\n",
        "        # For complex: Convert singular values to diagonal matrix in complex form\n",
        "        if np.iscomplexobj(batch_cpu):\n",
        "            Si = np.zeros((k, k), dtype=batch_cpu.dtype)\n",
        "            np.fill_diagonal(Si, S_cpu[i])\n",
        "        else:\n",
        "            Si = np.diag(S_cpu[i])       # Real diagonal matrix\n",
        "\n",
        "        recon_i = U_cpu[i] @ Si @ Vh_cpu[i]  # Reconstructed matrix\n",
        "\n",
        "        # Calculate Frobenius norm of the difference\n",
        "        diff = recon_i - Ai\n",
        "        if np.iscomplexobj(diff):\n",
        "            # For complex: norm = sqrt(sum(|z|^2))\n",
        "            err = np.sqrt(np.sum(np.real(diff * np.conj(diff))))\n",
        "        else:\n",
        "            err = 100. * np.linalg.norm(diff) / np.linalg.norm(Ai)\n",
        "\n",
        "        errors.append(err)\n",
        "\n",
        "    avg_error = np.mean(errors)\n",
        "    avg_errors.append(avg_error)\n",
        "\n",
        "    print(f\"Batch size B = {B:4d} → elapsed time = {elapsed_time:.6f} s, avg reconstruction error = {avg_error:.3e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c8OjDKsUMs7",
        "outputId": "bc3614f5-885b-47ae-b4ec-d761d8a2eb32"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size B =   32 → elapsed time = 0.033380 s, avg reconstruction error = 1.570e-13\n",
            "Batch size B =   64 → elapsed time = 0.002306 s, avg reconstruction error = 1.723e-13\n",
            "Batch size B =  128 → elapsed time = 0.004438 s, avg reconstruction error = 1.579e-13\n",
            "Batch size B =  256 → elapsed time = 0.007315 s, avg reconstruction error = 1.638e-13\n",
            "Batch size B =  512 → elapsed time = 0.013620 s, avg reconstruction error = 1.589e-13\n",
            "Batch size B = 1024 → elapsed time = 0.026597 s, avg reconstruction error = 1.617e-13\n",
            "Batch size B = 2048 → elapsed time = 0.052818 s, avg reconstruction error = 1.610e-13\n",
            "Batch size B = 4096 → elapsed time = 0.076113 s, avg reconstruction error = 1.615e-13\n",
            "Batch size B = 8192 → elapsed time = 0.115998 s, avg reconstruction error = 1.609e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of errors and timings"
      ],
      "metadata": {
        "id": "y8ciIoYuEaZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_array = np.array(batch_sizes)\n",
        "elapsed_array = np.array(elapsed_times)\n",
        "error_array = np.array(avg_errors)\n",
        "\n",
        "# Plot Timing vs. Batch Size (log-log scale)\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(B_array, elapsed_array, marker='o')\n",
        "plt.title(f\"Batched SVD Timing vs. Batch Size (m={m}, n={n})\")\n",
        "plt.xlabel(\"Batch Size (B)\")\n",
        "plt.ylabel(\"Elapsed Time (seconds)\")\n",
        "plt.xscale('log', base=2)\n",
        "plt.yscale('log')\n",
        "plt.grid(True, which='both', ls='--')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Average Reconstruction Error vs. Batch Size (log-log scale)\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(B_array, error_array, marker='o')\n",
        "plt.title(f\"Average Reconstruction Error vs. Batch Size (m={m}, n={n})\")\n",
        "plt.xlabel(\"Batch Size (B)\")\n",
        "plt.ylabel(\"Average Error (Frobenius Norm)\")\n",
        "plt.xscale('log', base=2)\n",
        "plt.yscale('log')\n",
        "plt.grid(True, which='both', ls='--')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qtWL2rU-UXPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the results"
      ],
      "metadata": {
        "id": "mvCZu0MN9c_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save data to CSV\n",
        "filename = \"resultsPyTorch.csv\"\n",
        "with open(filename, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"elapsed_time\", \"error\"])  # Header row\n",
        "    writer.writerows(zip(elapsed_times, errors))\n",
        "\n",
        "print(f\"Data saved to {filename}\")"
      ],
      "metadata": {
        "id": "ujd-KH9K9eKN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
