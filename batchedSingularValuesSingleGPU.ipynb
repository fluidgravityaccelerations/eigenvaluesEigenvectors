{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9QCN85uKMgN",
        "outputId": "76c29afc-cc30-4bd7-f28f-1d7ae563cb94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.11/dist-packages (2025.1.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.11/dist-packages (from pycuda) (2025.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.8)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Requirement already satisfied: siphash24>=1.6 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (1.7)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ASSUMPTION: Nrows <= Ncols**"
      ],
      "metadata": {
        "id": "JaUb5BNWEQ1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ITERATIONS ARE NOT POSSIBLE DUE TO THE CACHING MECHANISM OF PYCUDA AND THE TEMPLATE COMPILING NEEDS**"
      ],
      "metadata": {
        "id": "aGhhD_uVgk8S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHWd4FpeJW_u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as drv\n",
        "from pycuda.compiler import SourceModule"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numMatrices       = np.uint32(1048576)\n",
        "#numMatrices       = np.uint32(5)\n",
        "numMatrices       = np.uint32(4)\n",
        "Nrows             = np.uint32(4)\n",
        "Ncols             = np.uint32(4)\n",
        "maxIter           = np.uint32(Nrows)  # Bidiagonalization iterations\n",
        "\n",
        "if (Nrows < Ncols):\n",
        "  LEN = Nrows\n",
        "else:\n",
        "  LEN = Nrows - 1\n",
        "\n",
        "workType          = np.float64\n",
        "#workType          = np.float32\n",
        "if workType       == np.float32:\n",
        "    dtype_str     = \"float\"\n",
        "    sturmTol      = np.float32(1e-7)\n",
        "    #sturmTol      = np.float32(1e-6)\n",
        "else:\n",
        "    dtype_str     = \"double\"\n",
        "    sturmTol      = np.float64(1e-13)\n",
        "    #sturmTol      = np.float64(1e-12)"
      ],
      "metadata": {
        "id": "9oEgmGjAE7f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rearrange - Original storage of the matrices is columnwise, while output storage is interlaced rowwise."
      ],
      "metadata": {
        "id": "WtC4hlEMKE_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeRearrangeKernel(dtype_str, numMatrices, Nrows, Ncols):\n",
        "\n",
        "    return f\"\"\"\n",
        "    #define T {dtype_str}\n",
        "    #define numMatrices {numMatrices}\n",
        "    #define Nrows {Nrows}\n",
        "    #define Ncols {Ncols}\n",
        "\n",
        "    extern \"C\" {{\n",
        "    __global__ void rearrangeKernel(const T * __restrict__ inputMatrices, T * __restrict__ outputMatrices) {{\n",
        "        int tid = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "        if (tid < numMatrices) {{\n",
        "            #pragma unroll\n",
        "            for (unsigned int i = 0; i < Nrows; i++)\n",
        "                #pragma unroll\n",
        "                for (unsigned int j = 0; j < Ncols; j++)\n",
        "                    outputMatrices[ tid + j * numMatrices + i * (numMatrices * Ncols) ]\n",
        "                      = inputMatrices[ tid * (Nrows * Ncols) + j * Nrows + i ];\n",
        "        }}\n",
        "    }}\n",
        "    }}\"\"\""
      ],
      "metadata": {
        "id": "YedheE2IC2tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bidiagonalize - Assumes interlaced storage of the matrices"
      ],
      "metadata": {
        "id": "dQG31O4IKT0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeBidiagonalizeKernel(dtype_str, numMatrices, Nrows, Ncols):\n",
        "    \"\"\"\n",
        "    Restituisce la stringa CUDA per il kernel di bidiagonalizzazione,\n",
        "    assumendo che l’array d’ingresso sia già “rearrangiato” in formato\n",
        "    row-major interlacciato tra batch (output di rearrange).\n",
        "\n",
        "    - dtype_str: \"float\" o \"double\"\n",
        "    - numMatrices, Nrows, Ncols: costanti a compile-time\n",
        "    \"\"\"\n",
        "    return f\"\"\"\n",
        "    #define T {dtype_str}\n",
        "    #define numMatrices {numMatrices}\n",
        "    #define Nrows {Nrows}\n",
        "    #define Ncols {Ncols}\n",
        "\n",
        "    // ===============================================\n",
        "    // COMPUTE LEFT HOUSEHOLDER VECTORS (device function)\n",
        "    // ===============================================\n",
        "    __device__ __forceinline__ void computeLeftHouseholderVectors(\n",
        "        const T * __restrict__ inputMatrices,\n",
        "        T * __restrict__ outputLeftHouseholderVectors,\n",
        "        T &betaq,\n",
        "        const unsigned int tid,\n",
        "        const unsigned int iterCounter)\n",
        "    {{\n",
        "        T x0, norm2 = static_cast<T>(0), mu, v0;\n",
        "\n",
        "        #pragma unroll\n",
        "        for (unsigned int i = 0; i < iterCounter; i++)\n",
        "            outputLeftHouseholderVectors[i] = static_cast<T>(0);\n",
        "\n",
        "        // Leggiamo, per i = iterCounter+1 ... Nrows-1, l’elemento\n",
        "        // (row = i, col = iterCounter, batch = tid) nel layout interlacciato:\n",
        "        #pragma unroll\n",
        "        for (unsigned int i = iterCounter + 1; i < Nrows; i++)\n",
        "        {{\n",
        "            // offset interlacciato:\n",
        "            //    blocco di righe:    i * (numMatrices * Ncols)\n",
        "            //    blocco di colonne:  iterCounter * numMatrices\n",
        "            //    offset batch:       + tid\n",
        "            const unsigned int idx = i * (numMatrices * Ncols)\n",
        "                                   + iterCounter * numMatrices\n",
        "                                   + tid;\n",
        "            const T buffer = inputMatrices[idx];\n",
        "            outputLeftHouseholderVectors[i] = buffer;\n",
        "            norm2 += buffer * buffer;\n",
        "        }}\n",
        "\n",
        "        // x0 = elemento (row = iterCounter, col = iterCounter, batch = tid):\n",
        "        unsigned int idx_x0 = iterCounter * (numMatrices * Ncols)\n",
        "                            + iterCounter * numMatrices\n",
        "                            + tid;\n",
        "        x0 = inputMatrices[idx_x0];\n",
        "\n",
        "        if (norm2 == static_cast<T>(0))\n",
        "        {{\n",
        "            betaq = static_cast<T>(0);\n",
        "        }}\n",
        "        else\n",
        "        {{\n",
        "            mu = sqrt(x0 * x0 + norm2);\n",
        "            if (x0 <= static_cast<T>(0))\n",
        "                v0 = x0 - mu;\n",
        "            else\n",
        "                v0 = -norm2 / (x0 + mu);\n",
        "\n",
        "            T temp = static_cast<T>(1) / v0;\n",
        "            betaq = static_cast<T>(2) * ((v0 * v0) / (norm2 + (v0 * v0)));\n",
        "            outputLeftHouseholderVectors[iterCounter] = static_cast<T>(1);\n",
        "\n",
        "            #pragma unroll\n",
        "            for (unsigned int s = iterCounter + 1; s < Nrows; s++)\n",
        "                outputLeftHouseholderVectors[s] *= temp;\n",
        "        }}\n",
        "    }}\n",
        "\n",
        "    // ================================================\n",
        "    // COMPUTE RIGHT HOUSEHOLDER VECTORS (device function)\n",
        "    // ================================================\n",
        "    __device__ __forceinline__ void computeRightHouseholderVectors(\n",
        "        const T * __restrict__ inputVectors,\n",
        "        T * __restrict__ outputRightHouseholderVectors,\n",
        "        T &betap,\n",
        "        const unsigned int tid,\n",
        "        const unsigned int iterCounter)\n",
        "    {{\n",
        "        T x0, norm2 = static_cast<T>(0), mu, v0;\n",
        "\n",
        "        #pragma unroll\n",
        "        for (unsigned int i = 0; i < iterCounter + 1; i++)\n",
        "            outputRightHouseholderVectors[i] = static_cast<T>(0);\n",
        "\n",
        "        #pragma unroll\n",
        "        for (unsigned int i = iterCounter + 2; i < Ncols; i++)\n",
        "        {{\n",
        "            const T buffer = inputVectors[i];\n",
        "            outputRightHouseholderVectors[i] = buffer;\n",
        "            norm2 += buffer * buffer;\n",
        "        }}\n",
        "\n",
        "        x0 = inputVectors[iterCounter + 1];\n",
        "\n",
        "        if (norm2 == static_cast<T>(0))\n",
        "        {{\n",
        "            betap = static_cast<T>(0);\n",
        "        }}\n",
        "        else\n",
        "        {{\n",
        "            mu = sqrt(x0 * x0 + norm2);\n",
        "            if (x0 <= static_cast<T>(0))\n",
        "                v0 = x0 - mu;\n",
        "            else\n",
        "                v0 = -norm2 / (x0 + mu);\n",
        "\n",
        "            T temp = static_cast<T>(1) / v0;\n",
        "            betap = static_cast<T>(2) * ((v0 * v0) / (norm2 + v0 * v0));\n",
        "            outputRightHouseholderVectors[iterCounter + 1] = static_cast<T>(1);\n",
        "\n",
        "            #pragma unroll\n",
        "            for (unsigned int s = iterCounter + 2; s < Ncols; s++)\n",
        "                outputRightHouseholderVectors[s] *= temp;\n",
        "        }}\n",
        "    }}\n",
        "\n",
        "    extern \"C\" {{\n",
        "\n",
        "    // ===============================================\n",
        "    // GLOBAL KERNEL: bidiagonalizeKernel\n",
        "    // ===============================================\n",
        "    __global__ void bidiagonalizeKernel(\n",
        "        T *inputMatrices,           // batch di matrici, interlacciate row-major\n",
        "        const unsigned int maxIter) // massimo numero di iterazioni\n",
        "    {{\n",
        "        int tid = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "        if (tid >= numMatrices) return;\n",
        "\n",
        "        // Buffer temporanei per ciascun thread:\n",
        "        T leftHouseholderVectors[Nrows];\n",
        "        T rightHouseholderVectors[Ncols];\n",
        "        T inputVectorsForRight[Ncols];\n",
        "        T wi[Nrows];\n",
        "        T xi[Ncols];\n",
        "        T zi[Ncols];\n",
        "        T betau = static_cast<T>(0), betav = static_cast<T>(0);\n",
        "\n",
        "        // Iterazioni:\n",
        "        for (unsigned int iterCounter = 0; iterCounter < maxIter; iterCounter++)\n",
        "        {{\n",
        "            if (iterCounter < Ncols - 2)\n",
        "            {{\n",
        "                // 1) Compute left Householder\n",
        "                computeLeftHouseholderVectors(\n",
        "                    inputMatrices,\n",
        "                    leftHouseholderVectors,\n",
        "                    betau,\n",
        "                    tid,\n",
        "                    iterCounter);\n",
        "\n",
        "                // 2) Build inputVectorsForRight (per riflessioni right)\n",
        "                #pragma unroll\n",
        "                for (unsigned int j = 0; j < Ncols; j++)\n",
        "                {{\n",
        "                    T sum = static_cast<T>(0);\n",
        "                    #pragma unroll\n",
        "                    for (unsigned int i = 0; i < Nrows; i++)\n",
        "                    {{\n",
        "                        // leggo elemento (row=i, col=j) della matrice \"tid\" nel layout interlacciato:\n",
        "                        unsigned int idx_val = i * (numMatrices * Ncols)\n",
        "                                             + j * numMatrices\n",
        "                                             + tid;\n",
        "                        T val = inputMatrices[idx_val];\n",
        "                        sum += -betau * leftHouseholderVectors[i] * val;\n",
        "                    }}\n",
        "                    // aggiungo l’elemento diagonale (row=iterCounter, col=j) di A^(tid):\n",
        "                    unsigned int idx_diag = iterCounter * (numMatrices * Ncols)\n",
        "                                          + j * numMatrices\n",
        "                                          + tid;\n",
        "                    T diag = inputMatrices[idx_diag];\n",
        "                    inputVectorsForRight[j] = sum + diag;\n",
        "                    xi[j] = -sum;\n",
        "                }}\n",
        "\n",
        "                // 3) Compute right Householder\n",
        "                computeRightHouseholderVectors(\n",
        "                    inputVectorsForRight,\n",
        "                    rightHouseholderVectors,\n",
        "                    betav,\n",
        "                    tid,\n",
        "                    iterCounter);\n",
        "\n",
        "                // 4) Build wi\n",
        "                #pragma unroll\n",
        "                for (unsigned int i = 0; i < Nrows; i++)\n",
        "                {{\n",
        "                    T sum = static_cast<T>(0);\n",
        "                    #pragma unroll\n",
        "                    for (unsigned int j = 0; j < Ncols; j++)\n",
        "                    {{\n",
        "                        unsigned int idx_val = i * (numMatrices * Ncols)\n",
        "                                             + j * numMatrices\n",
        "                                             + tid;\n",
        "                        T val = inputMatrices[idx_val];\n",
        "                        sum += betav * rightHouseholderVectors[j] * val;\n",
        "                    }}\n",
        "                    wi[i] = sum;\n",
        "                }}\n",
        "\n",
        "                // 5) Build zi\n",
        "                T dot = static_cast<T>(0);\n",
        "                #pragma unroll\n",
        "                for (unsigned int i = 0; i < Ncols; i++)\n",
        "                    dot += xi[i] * rightHouseholderVectors[i];\n",
        "\n",
        "                #pragma unroll\n",
        "                for (unsigned int i = 0; i < Ncols; i++)\n",
        "                    zi[i] = xi[i] - betav * dot * rightHouseholderVectors[i];\n",
        "\n",
        "                // 6) Update matrix A^(tid)\n",
        "                #pragma unroll\n",
        "                for (unsigned int r = 0; r < Nrows; r++)\n",
        "                {{\n",
        "                    #pragma unroll\n",
        "                    for (unsigned int c = 0; c < Ncols; c++)\n",
        "                    {{\n",
        "                        unsigned int idx_old = r * (numMatrices * Ncols)\n",
        "                                             + c * numMatrices\n",
        "                                             + tid;\n",
        "                        T oldVal = inputMatrices[idx_old];\n",
        "                        T L = -leftHouseholderVectors[r] * zi[c];\n",
        "                        T R = -wi[r] * rightHouseholderVectors[c];\n",
        "                        inputMatrices[idx_old] = L + R + oldVal;\n",
        "                    }}\n",
        "                }}\n",
        "            }}\n",
        "            else\n",
        "            {{\n",
        "                // Ultima iterazione: solo left Householder\n",
        "                computeLeftHouseholderVectors(\n",
        "                    inputMatrices,\n",
        "                    leftHouseholderVectors,\n",
        "                    betau,\n",
        "                    tid,\n",
        "                    iterCounter);\n",
        "\n",
        "                // Build xi\n",
        "                #pragma unroll\n",
        "                for (unsigned int j = 0; j < Ncols; j++)\n",
        "                {{\n",
        "                    T sum = static_cast<T>(0);\n",
        "                    #pragma unroll\n",
        "                    for (unsigned int i = 0; i < Nrows; i++)\n",
        "                    {{\n",
        "                        unsigned int idx_val = i * (numMatrices * Ncols)\n",
        "                                             + j * numMatrices\n",
        "                                             + tid;\n",
        "                        T val = inputMatrices[idx_val];\n",
        "                        sum += leftHouseholderVectors[i] * val;\n",
        "                    }}\n",
        "                    xi[j] = sum;\n",
        "                }}\n",
        "\n",
        "                // Update matrix A^(tid)\n",
        "                #pragma unroll\n",
        "                for (unsigned int r = 0; r < Nrows; r++)\n",
        "                {{\n",
        "                    #pragma unroll\n",
        "                    for (unsigned int c = 0; c < Ncols; c++)\n",
        "                    {{\n",
        "                        unsigned int idx_old = r * (numMatrices * Ncols)\n",
        "                                             + c * numMatrices\n",
        "                                             + tid;\n",
        "                        T oldVal = inputMatrices[idx_old];\n",
        "                        inputMatrices[idx_old] = -betau * xi[c] * leftHouseholderVectors[r] + oldVal;\n",
        "                    }}\n",
        "                }}\n",
        "            }}\n",
        "        }}\n",
        "    }}\n",
        "    }}  // extern \"C\"\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "iGQP-K8SKc-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract diagonals - Assumes interlaced storage of matrices"
      ],
      "metadata": {
        "id": "PiQ4zQgJ_ako"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeExtractDiagonalsKernel(dtype_str, numMatrices, Nrows, Ncols):\n",
        "    return f\"\"\"\n",
        "    #define T {dtype_str}\n",
        "    #define numMatrices {numMatrices}\n",
        "    #define Nrows {Nrows}\n",
        "    #define Ncols {Ncols}\n",
        "\n",
        "    extern \"C\" {{\n",
        "\n",
        "    __global__ void extractDiagonalsKernel(\n",
        "        const T * __restrict__ inputMatrices,\n",
        "        T * __restrict__ d,\n",
        "        T * __restrict__ e)\n",
        "    {{\n",
        "        int tid = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "        if (tid >= numMatrices) return;\n",
        "\n",
        "        // estraiamo solo Nrows elementi per batch\n",
        "        #pragma unroll\n",
        "        for (unsigned int i = 0; i < Nrows - 1; i++) {{\n",
        "            // offset base: r = i, c = i\n",
        "            unsigned int base_diag = (i * Ncols + i) * numMatrices + tid;\n",
        "            d[ tid + i * numMatrices ] = inputMatrices[ base_diag ];\n",
        "\n",
        "            // offset super-diagonale: r = i, c = i+1\n",
        "            unsigned int base_sup  = (i * Ncols + (i + 1)) * numMatrices + tid;\n",
        "            e[ tid + i * numMatrices ] = inputMatrices[ base_sup ];\n",
        "        }}\n",
        "        // ultimo elemento diagonale (i = Nrows-1)\n",
        "        unsigned int i = Nrows - 1;\n",
        "        unsigned int base_last = (i * Ncols + i) * numMatrices + tid;\n",
        "        d[ tid + i * numMatrices ] = inputMatrices[ base_last ];\n",
        "        if (Ncols > Nrows) {{\n",
        "            unsigned int base_last = (i * Ncols + (i + 1)) * numMatrices + tid;\n",
        "            e[ tid + i * numMatrices ] = inputMatrices[ base_last ];\n",
        "        }}\n",
        "    }}\n",
        "    }}  // extern \"C\"\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "6_eF5AB4_iLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tridiagonal matrices computations"
      ],
      "metadata": {
        "id": "c7fCSfye3Azb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeTridiagonalMatricesComputationKernel(dtype_str, numMatrices, Nrows, Ncols, LEN):\n",
        "    return f\"\"\"\n",
        "    #define T {dtype_str}\n",
        "    #define numMatrices {numMatrices}\n",
        "    #define Nrows {Nrows}\n",
        "    #define Ncols {Ncols}\n",
        "    #define LEN {LEN}\n",
        "\n",
        "    extern \"C\" {{\n",
        "\n",
        "      __global__ void tridiagFromBidiagKernel(\n",
        "          const T * __restrict__ d,    // [numMatrices*Nrows] interlacciato\n",
        "          const T * __restrict__ e,    // [numMatrices*LEN_BETA] interlacciato\n",
        "                T * __restrict__ alpha,// [numMatrices*Ncols] interlacciato\n",
        "                T * __restrict__ beta) // [numMatrices*(Ncols-1)] interlacciato\n",
        "      {{\n",
        "          const unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "          if (tid >= numMatrices) return;\n",
        "\n",
        "          alpha[0 * numMatrices + tid] = d[0 * numMatrices + tid] * d[0 * numMatrices + tid];\n",
        "          beta [0 * numMatrices + tid] = d[0 * numMatrices + tid] * e[0 * numMatrices + tid];\n",
        "\n",
        "          // i = 1 … Nrows-1  (diagonale)\n",
        "          #pragma unroll\n",
        "          for (unsigned int i = 1; i < Nrows; ++i) {{\n",
        "                T di = d[i * numMatrices + tid];\n",
        "                T ei_1 = e[(i - 1) * numMatrices + tid];\n",
        "                alpha[i * numMatrices + tid] = di * di + ei_1 * ei_1;\n",
        "          }}\n",
        "\n",
        "          // βᵢ = dᵢ * eᵢ  per i = 1 … LEN -1\n",
        "          #pragma unroll\n",
        "          for (unsigned int i = 1; i < LEN; ++i)\n",
        "                  beta[i*numMatrices + tid] = d[i*numMatrices + tid] * e[i*numMatrices + tid];\n",
        "\n",
        "          #pragma unroll\n",
        "          for (unsigned int i = Nrows; i < Ncols; ++i) {{\n",
        "          //for (unsigned int i = Nrows; i < Nrows + 1; ++i) {{\n",
        "              // qui non c'è più d[i] ma solo e[i-1]\n",
        "              if (i == Nrows) {{\n",
        "                T ei_1 = e[(i - 1) * numMatrices + tid];\n",
        "                alpha[i * numMatrices + tid] = ei_1 * ei_1;\n",
        "              }}\n",
        "              else\n",
        "                alpha[i * numMatrices + tid] = T(0);\n",
        "          }}\n",
        "      }}\n",
        "\n",
        "    }} // extern \"C\"\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "vpJHBs4t3EQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pivots computation"
      ],
      "metadata": {
        "id": "ZYeBsKgYPzPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makePivotsComputationKernel(dtype_str, numMatrices, Nrows):\n",
        "    eps_str = \"FLT_EPSILON\" if dtype_str==\"float\" else \"DBL_EPSILON\"\n",
        "    return f\"\"\"\n",
        "    #define T {dtype_str}\n",
        "    #define numMatrices {numMatrices}\n",
        "    #define Nrows {Nrows}\n",
        "\n",
        "    #include <cfloat>\n",
        "\n",
        "\n",
        "    // pick machineâ€“epsilon for our T\n",
        "    #define eps {eps_str}\n",
        "\n",
        "    // Macro absolute / max\n",
        "    //#define fabsT(x) ((T)fabs(x))\n",
        "    __device__ __forceinline__ float  fabsT(float  x) {{ return fabsf(x); }}\n",
        "    __device__ __forceinline__ double fabsT(double x) {{ return fabs (x); }}\n",
        "    //#define fmaxT(x,y) ((T)fmax(x,y))\n",
        "    __device__ __forceinline__ float  fmaxT(float  x, float y) {{ return fmaxf(x, y); }}\n",
        "    __device__ __forceinline__ double fmaxT(double x, double y) {{ return fmax (x, y); }}\n",
        "\n",
        "    extern \"C\" {{\n",
        "\n",
        "    __global__ void pivotsComputationKernel(\n",
        "        const T * __restrict__ b,   // [numMatrices * LEN]\n",
        "              T * __restrict__ piv) // [numMatrices]\n",
        "    {{\n",
        "      unsigned tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "      if (tid >= numMatrices) return;\n",
        "\n",
        "      const unsigned LEN = Nrows - 1;\n",
        "      // Trovo il massimo assoluto di b[0..LEN-1]\n",
        "      T localMax = fabsT(b[0*numMatrices + tid]);\n",
        "      #pragma unroll\n",
        "      for (unsigned i = 1; i < LEN; ++i) {{\n",
        "        T v = fabsT(b[i*numMatrices + tid]);\n",
        "        if (v > localMax) localMax = fmaxT(localMax, v);\n",
        "      }}\n",
        "\n",
        "      // pivot = Î²_max * eps * safety_factor (qui scelto 10)\n",
        "      piv[tid] = localMax * eps * (T)5;\n",
        "    }}\n",
        "\n",
        "    }} // extern \"C\"\n",
        "\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "ktPRBSfLP0mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intervals computation"
      ],
      "metadata": {
        "id": "O65ua5z05UTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeComputeInitialIntervalsKernel(dtype_str, numMatrices, Nrows):\n",
        "    return f\"\"\"\n",
        "    #define T {dtype_str}\n",
        "    #define numMatrices {numMatrices}\n",
        "    #define Nrows {Nrows}\n",
        "\n",
        "    // file: initial_interval_kernel.cu\n",
        "    #include <cfloat>\n",
        "    #include <cmath>\n",
        "\n",
        "  __device__ __forceinline__ float  fabsT(float  x) {{ return fabsf(x); }}\n",
        "  __device__ __forceinline__ double fabsT(double x) {{ return fabs (x); }}\n",
        "\n",
        "    extern \"C\" {{\n",
        "\n",
        "    // ===============================================\n",
        "    // KERNEL: computeInitialIntervalKernel\n",
        "    // ===============================================\n",
        "    __global__ void computeInitialIntervalsKernel(\n",
        "        const T * __restrict__ d,       // [numMatrices * Nrows]\n",
        "        const T * __restrict__ b,       // [numMatrices * (Nrows-1)]  (se Nrows<=Ncols)\n",
        "    // output:\n",
        "        T * __restrict__ alpha_out,     // [numMatrices]\n",
        "        T * __restrict__ beta_out)      // [numMatrices]\n",
        "    {{\n",
        "        unsigned tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "        if (tid >= numMatrices) return;\n",
        "\n",
        "        // 1) prendo d[0], b[0]\n",
        "        T a = d[0*numMatrices + tid] - fabsT(b[0*numMatrices + tid]);\n",
        "        T be = fabsT(d[0*numMatrices + tid]) + fabsT(b[0*numMatrices + tid]);\n",
        "\n",
        "        // 2) ultimo elemento (i=Nrows-1) usa solo d[Nrows-1] e b[Nrows-2]\n",
        "        {{\n",
        "            unsigned i = Nrows-1;\n",
        "            T di   = d[i*numMatrices + tid];\n",
        "            T bi_1 = b[(i-1)*numMatrices + tid];\n",
        "            T t1   = di - fabsT(bi_1);\n",
        "            T t2   = fabsT(di) + fabsT(bi_1);\n",
        "            if (t1 < a)     a = t1;\n",
        "            if (t2 > be)    be = t2;\n",
        "        }}\n",
        "\n",
        "        // 3) generica i=1..Nrows-2\n",
        "        #pragma unroll\n",
        "        for (unsigned i = 1; i < Nrows-1; ++i) {{\n",
        "            T di    = d[i*numMatrices + tid];\n",
        "            T bi_1  = b[(i-1)*numMatrices + tid];\n",
        "            T bi    = b[i*numMatrices + tid];\n",
        "            T t1 = di - fabsT(bi_1) - fabsT(bi);\n",
        "            T t2 = di + fabsT(bi_1) + fabsT(bi);\n",
        "            if (t1 < a)  a = t1;\n",
        "            if (t2 > be) be = t2;\n",
        "        }}\n",
        "\n",
        "        alpha_out[tid] = a;\n",
        "        beta_out [tid] = be;\n",
        "    }}\n",
        "\n",
        "    }} // extern \"C\"\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "6uXpcfP85VsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roots computation"
      ],
      "metadata": {
        "id": "vJxvO5GRRZWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeRootsComputationKernel(dtype_str, numMatrices, Nrows, Ncols):\n",
        "    return f\"\"\"\n",
        "    #define T {dtype_str}\n",
        "    #define numMatrices {numMatrices}\n",
        "    #define Nrows {Nrows}\n",
        "    #define Ncols {Ncols}\n",
        "\n",
        "  __device__ __forceinline__ float  fabsT(float  x) {{ return fabsf(x); }}\n",
        "  __device__ __forceinline__ double fabsT(double x) {{ return fabs (x); }}\n",
        "\n",
        "  extern \"C\" {{\n",
        "  __global__ void sturmBisectionKernel(\n",
        "      const T* __restrict__ dd,           // diagonale tridiagonale interlacciata [numMatrices*Ncols]\n",
        "      const T* __restrict__ bb,           // off‑diagonale tridiagonale interlacciata [numMatrices*(Ncols‑1)]\n",
        "      const T* __restrict__ pivots,       // pivot per ciascuna matrice [numMatrices]\n",
        "      const T* __restrict__ alpha,        // estremi inferiori [numMatrices]\n",
        "      const T* __restrict__ beta,         // estremi superiori [numMatrices]\n",
        "      T*       __restrict__ singularVals, // output valori singolari [numMatrices*Nrows]\n",
        "      const T  tol)                       // tolleranza bisezione\n",
        "  {{\n",
        "      int tidx = blockIdx.x * blockDim.x + threadIdx.x;  // indice di matrice\n",
        "      int tidy = blockIdx.y * blockDim.y + threadIdx.y;                            // indice di autovalore\n",
        "\n",
        "      if (tidx >= numMatrices || tidy >= Nrows) return;\n",
        "\n",
        "      // 1) recupero intervallo e pivot\n",
        "      T a     = alpha[tidx];\n",
        "      T b     = beta [tidx];\n",
        "      T piv   = pivots[tidx];\n",
        "      T c     = (T)0;\n",
        "      unsigned numChanges;\n",
        "\n",
        "      // 2) bisezione\n",
        "      T dist = fabsT(b - a);\n",
        "      T s    = fabsT(b) + fabsT(a);\n",
        "      while (dist > tol * s) {{\n",
        "          c = (a + b) * (T)0.5;\n",
        "          // conto il numero di cambi di segno della sequenza di Sturm\n",
        "          numChanges = 0;\n",
        "          // primo termine\n",
        "          T q = dd[   tidx] - c;\n",
        "          if (fabsT(q) <= piv) q = -piv;\n",
        "          if (q < (T)0) ++numChanges;\n",
        "          // ricorriamo alla formula ricorsiva per i=2..Ncols\n",
        "          #pragma unroll\n",
        "          for (unsigned i = 2; i <= Ncols; ++i) {{\n",
        "              T di   = dd[   (i-1)*numMatrices + tidx];\n",
        "              T bi_1 = bb[(i-2)*numMatrices + tidx];\n",
        "              q = (di - (bi_1*bi_1)/q) - c;\n",
        "              if (fabsT(q) <= piv) q = -piv;\n",
        "              if (q < (T)0) ++numChanges;\n",
        "          }}\n",
        "          // se i numeri di radici ≤ c superano Ncols - (eigIndex+1), restringo a [a,c], altrimenti [c,b]\n",
        "          if (numChanges > (Ncols - (tidy + 1))) b = c;\n",
        "          else                                  a = c;\n",
        "\n",
        "          dist = fabsT(b - a);\n",
        "          s    = fabsT(b) + fabsT(a);\n",
        "      }}\n",
        "\n",
        "      // 3) scrivo la radice (= valore singolare) nell’output\n",
        "      singularVals[ tidy + tidx * Nrows ] = sqrt( fabsT(c) );\n",
        "  }}\n",
        "  }} // extern \"C\"\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "ApRyXPclc2LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilation"
      ],
      "metadata": {
        "id": "uz8iRDN6K4as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rearrangeKernel                 = SourceModule(makeRearrangeKernel(dtype_str, numMatrices, Nrows, Ncols), options=[\"--std=c++11\"], no_extern_c=True)\n",
        "bidiagonalizeKernel             = SourceModule(makeBidiagonalizeKernel(dtype_str, numMatrices, Nrows, Ncols), options=[\"--std=c++11\"], no_extern_c=True)\n",
        "extractDiagonalsKernel          = SourceModule(makeExtractDiagonalsKernel(dtype_str, numMatrices, Nrows, Ncols), options=[\"--std=c++11\"], no_extern_c=True)\n",
        "tridiagonalizeKernel            = SourceModule(makeTridiagonalMatricesComputationKernel(dtype_str, numMatrices, Nrows, Ncols, LEN), options=[\"--std=c++11\"], no_extern_c=True)\n",
        "pivotsComputationKernel         = SourceModule(makePivotsComputationKernel(dtype_str, numMatrices, Nrows), options=[\"--std=c++11\"], no_extern_c=True)\n",
        "computeInitialIntervalsKernel   = SourceModule(makeComputeInitialIntervalsKernel(dtype_str, numMatrices, Nrows), options=[\"--std=c++11\"], no_extern_c=True)\n",
        "rootsComputationKernel          = SourceModule(makeRootsComputationKernel(dtype_str, numMatrices, Nrows, Ncols), options=[\"--std=c++11\"], no_extern_c=True)"
      ],
      "metadata": {
        "id": "SAJryuwDK6X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recover the function pointers"
      ],
      "metadata": {
        "id": "JoYwILz7LIpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rearrange               = rearrangeKernel.get_function(\"rearrangeKernel\")\n",
        "bidiagonalize           = bidiagonalizeKernel.get_function(\"bidiagonalizeKernel\")\n",
        "extractDiagonals        = extractDiagonalsKernel.get_function(\"extractDiagonalsKernel\")\n",
        "tridiagonalize          = tridiagonalizeKernel.get_function(\"tridiagFromBidiagKernel\")\n",
        "pivotsComputation       = pivotsComputationKernel.get_function(\"pivotsComputationKernel\")\n",
        "intervalsComputation    = computeInitialIntervalsKernel.get_function(\"computeInitialIntervalsKernel\")\n",
        "rootsComputation        = rootsComputationKernel.get_function(\"sturmBisectionKernel\")"
      ],
      "metadata": {
        "id": "dLApZFm5LDrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeBatchedSVs(input_gpu_f, output_gpu_f, d_d, d_e, d_dd, d_bb, d_piv, d_alpha, d_beta, d_sv, numMatrices, Nrows, Ncols, workType):\n",
        "\n",
        "  bytes_per_elem      = np.dtype(workType).itemsize\n",
        "\n",
        "  blockSize           = 32\n",
        "  gridSize            = (int(numMatrices) + blockSize - 1) // blockSize  # = 1\n",
        "\n",
        "  #########################\n",
        "  # MATRIX REARRANGEMENTS #\n",
        "  #########################\n",
        "  rearrange(input_gpu_f, output_gpu_f, block=(blockSize,1,1), grid=(gridSize,1))\n",
        "  drv.Context.synchronize()\n",
        "  #print('rearrange done')\n",
        "\n",
        "  # --- Check tridiagonal extraction\n",
        "  '''h_output_gpu_f = np.zeros(numMatrices * Ncols * Nrows,     dtype=workType)\n",
        "  drv.memcpy_dtoh(h_output_gpu_f, output_gpu_f)\n",
        "\n",
        "  # Reshape and print for each matrix in batch\n",
        "  for k in range(numMatrices):\n",
        "      diag   = h_output_gpu_f   [k::numMatrices]      # picks [d0,d1,...] for batch k\n",
        "      print(f\"Rearrange batch {k}: matrix = {diag}\")'''\n",
        "\n",
        "  #####################\n",
        "  # BIDIAGONALIZATION #\n",
        "  #####################\n",
        "  bidiagonalize(output_gpu_f, maxIter, block=(blockSize,1,1), grid=(gridSize,1) )\n",
        "  drv.Context.synchronize()\n",
        "  #print('bidiagonalize done')\n",
        "\n",
        "  #####################\n",
        "  # EXTRACT DIAGONALS #\n",
        "  #####################\n",
        "  extractDiagonals(output_gpu_f, d_d, d_e, block=(blockSize,1,1), grid=(gridSize,1,1))\n",
        "  drv.Context.synchronize()\n",
        "  #print('extractDiagonals done')\n",
        "\n",
        "  ######################################################\n",
        "  # TRIDIAGONAL MATRICES COMPUTATIONS FROM BIDIAGONALS #\n",
        "  ######################################################\n",
        "  tridiagonalize(d_d, d_e, d_dd, d_bb, block=(blockSize,1,1), grid=(gridSize,1) )\n",
        "  drv.Context.synchronize()\n",
        "  #print('tridiagonalize done')\n",
        "\n",
        "  # --- Check tridiagonal extraction\n",
        "  '''h_dd = np.zeros(numMatrices * Ncols,     dtype=workType)\n",
        "  h_bb = np.zeros(numMatrices * (Ncols - 1), dtype=workType)\n",
        "  drv.memcpy_dtoh(h_dd, d_dd)\n",
        "  drv.memcpy_dtoh(h_bb, d_bb)\n",
        "\n",
        "  # Reshape and print for each matrix in batch\n",
        "  for k in range(numMatrices):\n",
        "      diag   = h_dd   [k::numMatrices]      # picks [d0,d1,...] for batch k\n",
        "      offdiag= h_bb   [k::numMatrices]      # picks [e0,e1,...] for batch k\n",
        "      print(f\"Batch {k}: dd = {diag}, ee = {offdiag}\")'''\n",
        "\n",
        "\n",
        "  ######################\n",
        "  # PIVOTS COMPUTATION #\n",
        "  ######################\n",
        "  pivotsComputation(d_bb, d_piv, block=(blockSize,1,1), grid=(gridSize,1) )\n",
        "  drv.Context.synchronize()\n",
        "  #print('pivotsComputation done')\n",
        "\n",
        "  #####################\n",
        "  # COMPUTE INTERVALS #\n",
        "  #####################\n",
        "  intervalsComputation(d_dd, d_bb, d_alpha, d_beta, block=(blockSize,1,1), grid=(gridSize,1))\n",
        "  drv.Context.synchronize()\n",
        "  #print('intervalsComputation done')\n",
        "\n",
        "  # --- Check interval computation\n",
        "  '''h_alpha = np.zeros(numMatrices,     dtype=workType)\n",
        "  h_beta = np.zeros(numMatrices, dtype=workType)\n",
        "  drv.memcpy_dtoh(h_alpha, d_alpha)\n",
        "  drv.memcpy_dtoh(h_beta, d_beta)\n",
        "\n",
        "  # Reshape and print for each matrix in batch\n",
        "  for k in range(numMatrices):\n",
        "      diag   = h_alpha   [k::numMatrices]      # picks [d0,d1,...] for batch k\n",
        "      offdiag= h_beta   [k::numMatrices]      # picks [e0,e1,...] for batch k\n",
        "      print(f\"Compute intervals batch {k}: alpha = {diag}, beta = {offdiag}\")'''\n",
        "\n",
        "  #####################\n",
        "  # ROOTS COMPUTATION #\n",
        "  #####################\n",
        "\n",
        "  bx = 16\n",
        "  by = 16\n",
        "  gx = (int(numMatrices) + bx - 1) // bx\n",
        "  gy = (int(Nrows) + by - 1) // by\n",
        "\n",
        "  rootsComputation(d_dd, d_bb, d_piv, d_alpha, d_beta, d_sv, sturmTol, block=(bx, by, 1), grid=(gx, gy, 1))\n",
        "  drv.Context.synchronize()\n",
        "  #print('rootsComputation done')"
      ],
      "metadata": {
        "id": "nOsJlZ57V9y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standard random matrix generation"
      ],
      "metadata": {
        "id": "pw0luXlLYsnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h_matrices = np.asfortranarray(\n",
        "    np.random.randn(numMatrices, Nrows, Ncols).astype(workType)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pkukY00JPK-i",
        "outputId": "42bfbfa1-9597-48ac-f66c-cae1e61fb193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'h_matrices = np.asfortranarray(\\n    np.random.randn(numMatrices, Nrows, Ncols).astype(workType)\\n)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random matrix generation according to a prescribed pattern of the singular values."
      ],
      "metadata": {
        "id": "rL6fcT0xYzGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''m = Nrows = Ncols\n",
        "\n",
        "base_kappas = np.array([2,4,6,8,10])\n",
        "# e.g. repeat each value 10 times\n",
        "kappas = np.repeat(base_kappas, numMatrices // len(base_kappas))\n",
        "# if numMatrices isn't a multiple of 5, append a few more to reach it:\n",
        "while kappas.size < numMatrices:\n",
        "    kappas = np.concatenate([kappas, base_kappas[: (numMatrices - kappas.size)]])\n",
        "# preallocate\n",
        "batch = np.empty((numMatrices, m, m), dtype=workType, order='F')\n",
        "\n",
        "for j, κ in enumerate(kappas):\n",
        "    # 1) geometric spectrum from cond=1 to cond=10^κ\n",
        "    s = 10**np.linspace(0, κ, m)\n",
        "\n",
        "    # 2) random orthonormal U, V via QR\n",
        "    #    (np.linalg.qr returns Q,R; we only need Q)\n",
        "    U, _ = np.linalg.qr(np.random.randn(m, m))\n",
        "    V, _ = np.linalg.qr(np.random.randn(m, m))\n",
        "\n",
        "    # 3) assemble\n",
        "    A = U @ np.diag(s) @ V.T\n",
        "\n",
        "    # store (astype and Fortran‐order)\n",
        "    batch[j, :, :] = A.astype(workType, copy=False)\n",
        "\n",
        "# ensure entire batch is Fortran‐contiguous\n",
        "h_matrices = np.asfortranarray(batch)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "PmMEdK55PM4h",
        "outputId": "90647d84-70b1-43e0-eb44-04464588e378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"m = Nrows = Ncols\\n\\nbase_kappas = np.array([2,4,6,8,10])\\n# e.g. repeat each value 10 times\\nkappas = np.repeat(base_kappas, numMatrices // len(base_kappas))\\n# if numMatrices isn't a multiple of 5, append a few more to reach it:\\nwhile kappas.size < numMatrices:\\n    kappas = np.concatenate([kappas, base_kappas[: (numMatrices - kappas.size)]])\\n# preallocate\\nbatch = np.empty((numMatrices, m, m), dtype=workType, order='F')\\n\\nfor j, κ in enumerate(kappas):\\n    # 1) geometric spectrum from cond=1 to cond=10^κ\\n    s = 10**np.linspace(0, κ, m)\\n\\n    # 2) random orthonormal U, V via QR\\n    #    (np.linalg.qr returns Q,R; we only need Q)\\n    U, _ = np.linalg.qr(np.random.randn(m, m))\\n    V, _ = np.linalg.qr(np.random.randn(m, m))\\n\\n    # 3) assemble\\n    A = U @ np.diag(s) @ V.T\\n\\n    # store (astype and Fortran‐order)\\n    batch[j, :, :] = A.astype(workType, copy=False)\\n\\n# ensure entire batch is Fortran‐contiguous\\nh_matrices = np.asfortranarray(batch)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random matrix generation by perturbing a fixed random matrix"
      ],
      "metadata": {
        "id": "7WZzfjpsZ4Wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''from numpy.linalg import norm\n",
        "\n",
        "# Parameters\n",
        "m = Nrows = Ncols            # assume square\n",
        "\n",
        "epsilons = np.array([1e-8, 1e-7, 1e-6, 1e-5], dtype=workType)\n",
        "\n",
        "# 1) Build your “clean” base matrix A\n",
        "#    For example: a random Gaussian, or reuse one from your Experiment 2\n",
        "A = np.random.randn(m, m).astype(workType, copy=False)\n",
        "\n",
        "# Precompute its 2‐norm\n",
        "A_norm2 = norm(A, 2)\n",
        "\n",
        "# 2) Allocate batch container [J × m × m] in Fortran order\n",
        "J = epsilons.size\n",
        "batch = np.empty((J, m, m), dtype=workType, order='F')\n",
        "\n",
        "# 3) Fill in each noisy realization\n",
        "for j, eps in enumerate(epsilons):\n",
        "    # draw noise matrix G ~ N(0,1)\n",
        "    G = np.random.randn(m, m).astype(workType, copy=False)\n",
        "    # form noisy matrix\n",
        "    batch[j, :, :] = (A + eps * A_norm2 * G)\n",
        "\n",
        "# 4) Ensure Fortran‐contiguity (batch was created as such)\n",
        "h_matrices = np.asfortranarray(batch)'''"
      ],
      "metadata": {
        "id": "B_Pyy6dTaIRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the random matrices\n",
        "h_input_col = np.zeros(numMatrices * Nrows * Ncols, dtype=workType)\n",
        "for k in range(numMatrices):\n",
        "    h_input_col[k*(Nrows*Ncols):(k+1)*(Nrows*Ncols)] = h_matrices[k].flatten(order='F')\n",
        "\n",
        "input_gpu_f       = drv.mem_alloc(h_input_col.nbytes)\n",
        "drv.memcpy_htod(input_gpu_f, h_input_col)\n",
        "\n",
        "bytes_per_elem      = np.dtype(workType).itemsize\n",
        "d_sv                = drv.mem_alloc(int(numMatrices * Nrows * bytes_per_elem))\n",
        "\n",
        "h_sv                = np.zeros(numMatrices * Nrows, dtype=workType);\n",
        "\n",
        "output_gpu_f        = drv.mem_alloc(int(numMatrices * Ncols * Nrows * bytes_per_elem))\n",
        "\n",
        "# Allocate GPU space for diagonals\n",
        "size_d              = numMatrices * Nrows * bytes_per_elem\n",
        "size_e              = numMatrices * LEN   * bytes_per_elem\n",
        "d_d                 = drv.mem_alloc(int(size_d))                                  # --- Main diagonal of the bidiagonal matrix\n",
        "d_e                 = drv.mem_alloc(int(size_e))                                  # --- Upper diagonal of the bidiagonal matrix\n",
        "\n",
        "size_dd             = numMatrices * Ncols * bytes_per_elem\n",
        "size_bb             = numMatrices * (Ncols - 1) * bytes_per_elem\n",
        "d_dd                = drv.mem_alloc(int(size_dd))                                 # --- alpha tridiagonal\n",
        "d_bb                = drv.mem_alloc(int(size_bb))                                 # --- beta tridiagonal\n",
        "\n",
        "size_piv            = numMatrices * bytes_per_elem\n",
        "d_piv               = drv.mem_alloc(int(size_piv))\n",
        "\n",
        "size_alpha_beta     = numMatrices * bytes_per_elem\n",
        "d_alpha             = drv.mem_alloc(int(size_alpha_beta))\n",
        "d_beta              = drv.mem_alloc(int(size_alpha_beta))"
      ],
      "metadata": {
        "id": "hjWKAqfGizN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Warmup execution"
      ],
      "metadata": {
        "id": "yI4BSLW067lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "computeBatchedSVs(input_gpu_f, output_gpu_f, d_d, d_e, d_dd, d_bb, d_piv, d_alpha, d_beta, d_sv, numMatrices, Nrows, Ncols, workType)\n",
        "drv.memcpy_dtoh(h_sv, d_sv)\n",
        "sv_matrix         = h_sv.reshape((numMatrices, Nrows), order='C')\n",
        "\n",
        "err_avg = 0.\n",
        "for k in range(numMatrices):\n",
        "    A_k = h_matrices[k]\n",
        "    s = np.linalg.svd(A_k, compute_uv=False)\n",
        "    # Compare only the first min(Nrows, Ncols) singular values\n",
        "    err = 100. * np.linalg.norm(s - sv_matrix[k][:min(Nrows, Ncols)]) / np.linalg.norm(s)\n",
        "    print(err)\n",
        "    #print(s)\n",
        "    err_avg += err\n",
        "\n",
        "err_avg = err_avg / numMatrices\n",
        "    #print(f\"Matrix {k}:  numpy SVD singular values = {s}\")\n",
        "    #print(f\"Matrix {k}: \", sv_matrix[k])\n",
        "\n",
        "print(f\"Batch size numMatrices = {numMatrices} → avg error: {err_avg:.3e}\")"
      ],
      "metadata": {
        "id": "wYTVgRZV69If",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6853e2-7d2f-4acf-fc3d-8a8041e3fd22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4258969916499614e-12\n",
            "3.3036979039454832e-12\n",
            "3.4929352991204703e-12\n",
            "2.7666183258485706e-12\n",
            "Batch size numMatrices = 4 → avg error: 2.997e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "True execution"
      ],
      "metadata": {
        "id": "90H5goyZa4xH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare CUDA events for timing\n",
        "start = drv.Event()\n",
        "end   = drv.Event()\n",
        "# Record start\n",
        "start.record()\n",
        "computeBatchedSVs(input_gpu_f, output_gpu_f, d_d, d_e, d_dd, d_bb, d_alpha, d_beta, d_piv, d_sv, numMatrices, Nrows, Ncols, workType)\n",
        "end.record()\n",
        "end.synchronize()\n",
        "elapsed_ms = start.time_till(end)\n",
        "\n",
        "#h_sv              = np.zeros(numMatrices * Nrows, dtype=workType)\n",
        "drv.memcpy_dtoh(h_sv, d_sv)\n",
        "sv_matrix         = h_sv.reshape((numMatrices, Nrows), order='C')\n",
        "\n",
        "#print(\"\\n=== Comparison with NumPy SVD ===\")\n",
        "err_avg = 0.\n",
        "for k in range(numMatrices):\n",
        "    A_k = h_matrices[k]\n",
        "    s = np.linalg.svd(A_k, compute_uv=False)\n",
        "    #err = 100. * np.linalg.norm(s - sv_matrix[k]) / np.linalg.norm(s)\n",
        "    err_avg += 100. * np.linalg.norm(s - sv_matrix[k][:min(Nrows, Ncols)]) / np.linalg.norm(s)\n",
        "    #print(f\"Matrix {k}: \", sv_matrix[k])\n",
        "    #print(f\"Matrix {k}:  numpy SVD singular values = {s}\")\n",
        "\n",
        "err_avg = err_avg / numMatrices\n",
        "\n",
        "print(f\"Batch size numMatrices = {numMatrices} → elapsed: {elapsed_ms / 1000:.6f} s, avg error: {err_avg:.3e}\")"
      ],
      "metadata": {
        "id": "bWr_sBt5a6E3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43474e6-6719-48df-ffd8-c2c7a05b3193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size numMatrices = 4 → elapsed: 0.000624 s, avg error: 2.997e-12\n"
          ]
        }
      ]
    }
  ]
}