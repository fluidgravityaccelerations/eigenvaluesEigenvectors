{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0yO7F8LJDYaa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure CUDA is available"
      ],
      "metadata": {
        "id": "qnYBcKJ0DdHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.cuda.is_available(), \"CUDA must be available to run this code on GPU.\"\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "okcsN9rXDiDg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "User-configurable parameters"
      ],
      "metadata": {
        "id": "VWfBpzw_-QMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dtype = torch.complex128\n",
        "dtype = torch.float64"
      ],
      "metadata": {
        "id": "mVyJF8Ua-PkL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = 4               # number of rows (fixed)\n",
        "n = 4               # number of columns (fixed)\n",
        "batch_sizes = [32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]"
      ],
      "metadata": {
        "id": "pXf74b1zMeko"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Warm-up execution"
      ],
      "metadata": {
        "id": "MwqUxpnpMjIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Warm-up to initialize CUDA context correctly for both real and complex:\n",
        "if dtype in (torch.complex64, torch.complex128):\n",
        "    # generate real and imaginary parts on GPU\n",
        "    float_dtype = torch.float32 if dtype==torch.complex64 else torch.float64\n",
        "    real = torch.randn(1, m, n, dtype=float_dtype, device=device)\n",
        "    imag = torch.randn(1, m, n, dtype=float_dtype, device=device)\n",
        "    # combine into a true complex tensor\n",
        "    warm_up = torch.complex(real, imag)\n",
        "else:\n",
        "    warm_up = torch.randn(1, m, n, dtype=dtype, device=device)\n",
        "\n",
        "# now do the SVD-values warm-up\n",
        "S_warm_up = torch.linalg.svdvals(warm_up)\n",
        "torch.cuda.synchronize()"
      ],
      "metadata": {
        "id": "3c8OjDKsUMs7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate over the batch size"
      ],
      "metadata": {
        "id": "t5JjEowIENMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elapsed_times = []\n",
        "avg_sv_errors = []\n",
        "\n",
        "for B in batch_sizes:\n",
        "    # ── 1) Create a random batch on CPU (NumPy) with specified dtype ──\n",
        "    if dtype in [torch.complex64, torch.complex128]:\n",
        "        # Generate complex data (real + imaginary parts)\n",
        "        real_part = np.random.randn(B, m, n).astype(np.float32 if dtype == torch.complex64 else np.float64)\n",
        "        imag_part = np.random.randn(B, m, n).astype(np.float32 if dtype == torch.complex64 else np.float64)\n",
        "        batch_cpu = real_part + 1j * imag_part\n",
        "    else:\n",
        "        # Generate real data\n",
        "        batch_cpu = np.random.randn(B, m, n).astype(np.float32 if dtype == torch.float32 else np.float64)\n",
        "\n",
        "    # 2) Move to GPU\n",
        "    X = torch.from_numpy(batch_cpu).to(device=device, dtype=dtype)\n",
        "\n",
        "    # 3) Time only-the-values SVD\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end   = torch.cuda.Event(enable_timing=True)\n",
        "    torch.cuda.synchronize()\n",
        "    start.record()\n",
        "\n",
        "    S_gpu = torch.linalg.svdvals(X)\n",
        "\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_times.append(start.elapsed_time(end) * 1e-3)\n",
        "\n",
        "    # 4) Bring back to CPU\n",
        "    S_gpu_cpu = S_gpu.cpu().numpy()  # shape (B, k)\n",
        "\n",
        "    # 5) Compute reference singular values & error\n",
        "    errors = []\n",
        "    for i in range(B):\n",
        "        Ai = batch_cpu[i]\n",
        "        S_ref = np.linalg.svd(Ai, compute_uv=False)\n",
        "        # sort descending (torch and numpy both return sorted SVs)\n",
        "        err = np.linalg.norm(S_gpu_cpu[i] - S_ref) / np.linalg.norm(S_ref)\n",
        "        errors.append(err)\n",
        "\n",
        "    avg_sv_errors.append(np.mean(errors))\n",
        "    print(f\"B={B:4d} → time={elapsed_times[-1]:.6f}s, avg rel SV-error={avg_sv_errors[-1]:.2e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dylzOSHIMpr2",
        "outputId": "2cbf54bc-bda6-4455-9f3f-9cd1c2c96050"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B=  32 → time=0.031204s, avg rel SV-error=8.37e-16\n",
            "B=  64 → time=0.002630s, avg rel SV-error=7.64e-16\n",
            "B= 128 → time=0.005414s, avg rel SV-error=7.87e-16\n",
            "B= 256 → time=0.008200s, avg rel SV-error=7.99e-16\n",
            "B= 512 → time=0.030365s, avg rel SV-error=7.45e-16\n",
            "B=1024 → time=0.026955s, avg rel SV-error=7.50e-16\n",
            "B=2048 → time=0.053343s, avg rel SV-error=7.50e-16\n",
            "B=4096 → time=0.101542s, avg rel SV-error=7.64e-16\n",
            "B=8192 → time=0.181040s, avg rel SV-error=7.54e-16\n",
            "B=16384 → time=0.188657s, avg rel SV-error=7.66e-16\n",
            "B=32768 → time=0.306101s, avg rel SV-error=7.63e-16\n",
            "B=65536 → time=0.612079s, avg rel SV-error=7.60e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the results"
      ],
      "metadata": {
        "id": "mvCZu0MN9c_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save data to CSV\n",
        "filename = \"resultsPyTorch.csv\"\n",
        "with open(filename, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"elapsed_time\", \"error\"])  # Header row\n",
        "    writer.writerows(zip(elapsed_times, errors))\n",
        "\n",
        "print(f\"Data saved to {filename}\")"
      ],
      "metadata": {
        "id": "ujd-KH9K9eKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2f6de1-55eb-4455-d2b2-680cc160da8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to resultsPyTorch.csv\n"
          ]
        }
      ]
    }
  ]
}
